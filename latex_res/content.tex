% --------------------------------------------------------------------

\section{Introduction}

In the past fifteen years, 
there have been rapid advances in the algorithms for combinatorial problems. 
This has been greatly sparked by the development in algebraic techniques for solving the 
multilinear monomial detection problem, that is, 
deciding whether a multivariate (multiple variables) 
polynomial contains a multilinear monomial 
(i.e., a term with multiple variables where each variable appears at most once, 
see also \Cref{sect:prelims_algebra}). 
This particular problem has proven to be fundamental since many combinatorial 
problems can be reduced to it. 
The idea of multilinear monomial detection 
for parameterized combinatorial problems was 
first introduced by \citeauthor{Koutis05} in an early work 
\cite{Koutis05}, where a set packing problem is 
reduced to multilinear monomial detection.

The technique of \emph{algebraic fingeprinting},   
introduced by \textcite{Koutis08} and further developed by 
\textcite{Williams09}, is used for detecting multilinear monomials,  
and has found great success for many combinatorial problems. 
For instance with algebraic fingerprinting, the $k$-path problem 
that previously could be solved in \bigOstar{4^{k}} 
time\footnote{$\mathcal{O}$* may hide factors polynomial to input size.} 
by \textcite{Chen07}, 
can now be solved in \bigOstar{2^{3k/2}} time \cite{Koutis08}. 
This result was quickly improved by \textcite{Williams09}, 
who gave an \bigOstar{2^k} algorithm.

Most famously, 
\textcite{Björklund14} published an algorithm 
that solved the famous Hamiltonian path problem (Hamiltonicity) in \bigOstar{1.657^n} time 
with clever utilizations of this novel algebraic technique. 
The fastest algorithms for Hamiltonicity before this ran in \bigOstar{2^n} time 
and date from \citeyear{HelKar62} \cite{HelKar62, Bellman62}. 
This was a significant improvement on a well-studied problem 
that had seen no progress in nearly fifty years! 
Soon thereafter, an \bigOstar{1.657^k} algorithm was found
for the parameterized version of the problem, the $k$-path problem, 
by using similar ideas as with Hamiltonicity \cite{Björklund17}.

\subsection{Research scope and thesis structure}

The goals of this bachelor's thesis are 
to find out how multilinear monomial detection is relevant in combinatorial problems, 
and how algebraic fingerprints can be utilized to design faster 
algorithms for these problems. For the reader new to this field of study, 
this thesis overviews a clever use of algebra in theoretical computer science, 
that is the technique of algebraic fingerprinting.

In the rest of this introduction, 
we discuss the relation of combinatorics and 
polynomials, build into the algebrization of combinatorial problems, and 
define the multilinear monomial detection problem as a prelude for the thesis. 
Finally in \Cref{sect:related_problems}, 
we overview the area of problems where this technique proves useful.

\Cref{sect:prelims} gives necessary 
preliminaries for the reader. In \Cref{sect:general_mld}, we 
dive into the technique of algebraic fingerprints, and solve the 
multilinear monomial detection problem with algebraic means. 
\Cref{sect:improvements} briefly overviews ideas for 
improvement in the domain of the general algebraic technique. 
\Cref{sect:conclusion} concludes the thesis.

\subsection{Algebrization of combinatorial problems}
\label{sect:algebrization}

A combinatorial problem asks whether a given 
finite set of objects satisfies some given constraints. 
For example, the $k$-path problem asks for, given a finite set of vertices and edges, 
a simple path (i.e., a path where each vertex is visited only once) of $k$ vertices. 
The solutions and non-solutions (solution candidate space) 
to combinatorial problems can be thought of as 
combinations of the given objects. 
The solution candidate space for the $k$-path problem 
consists of combinations of $k-1$ edges, where 
a valid solution combination consists of edges that are joint but 
share a vertex with at most one other edge.

\textcite{Valiant92} observed that 
multivariate polynomials have natural combinatorial interpretations. 
Now, we see how combinatorics may be represented with multivariate polynomials. 
We may think of a polynomial in its sum of monomials 
form (i.e., an expression with only additions of products) 
as a set of combinations. For instance, imagine a set of elements $M = \{a, b, c\}$. 
The polynomial $C = a+b+c$ represents all the possible choices 
if we are to pick an element from $M$. Following the standard idea behind polynomial 
multiplication, we see that the polynomial 
\[
  C^2 = (a+b+c)(a+b+c) = aa + ab + ac + ba + bb + bc + ca + cb + cc
\]
represents 
all possible combinations if we are to pick twice from $M$. 
Indeed, the polynomial $C^k$ represents all combinations of $k$ elements from $M$.

Utilizing this idea, \textcite{Koutis05} 
managed to reduce a combinatorial problem 
into an algebraic one, that is, multilinear monomial detection. 
In multilinear monomial detection, we represent the combinatorial problem 
as a polynomial where the solution candidates are encoded as follows: 
the non-solutions correspond to non-multilinear terms, 
and valid solutions to multilinear terms. 

Note, however, that detecting a multilinear monomial is not trivial: 
we are not given the polynomial (the problem input) as a sum of monomials. 
Instead, we are given an \emph{arithmetic circuit}
\footnote{see \Cref{sect:prelims_circuits} for information on arithmetic circuits} 
representing the polynomial, 
e.g., merely the expression $C^2$ in the example above. 
As we see in the next section, this is significant for the detection complexity.

Appropriate definitions for the indeterminates for $M$,
i.e. proper algebrizations, are problem-specific. 
In what follows, we give an example 
reduction to multilinear monomial detection; 
we algebrize the $k$-3D matching problem which is defined as follows:
\begin{problem}
  \problemtitle{$k$-\textsc{3D matching}}
  \probleminput{Three disjoint sets $A$, $B$ and $C$, 
  and a set of triples $T\subseteq A\times B\times C$.}
  \problemquestion{Is there a subset $M\subseteq T$, such that $\abs{M} = k$ and 
  the all the triples $m \in M$ are disjoint?}
\end{problem}

We begin by defining new indeterminates corresponding to the elements in $A$, $B$ and $C$, 
labeled as $a_i$, $b_j$ and $c_k$, respectively, where $i\in [\:\abs{A}\:]$, $j\in
[\:\abs{B}\:]$ and $k\in [\:\abs{C}\:]$ such that $[\:n\:] = \{1,\ldots,n\}$. 

For every triple $t \in T$, we define a multilinear monomial $x$ that is a
product of the elements in $t$. 
We denote the set of those monomials as $X$. 
Thus, $(a,b,c) \in T \implies abc \in X$.
From an algebraic perspective, we form monomials in the commutative polynomial 
ring $\Z[X]$ (i.e., polynomials that have coefficients from $\Z$ and variables from $X$, 
see also \Cref{sect:prelims_algebra}).

Next, we define the multivariate polynomial 
$P_k \in \Z[X]$ for $k \in \N$ iteratively 
as follows: 
\[
  P_1 = \displaystyle \sum_{x \in X}x, \: \: \: P_k = P_1^k
\]
Following this construction, we observe that $P_k$, 
when expanded into a sum of multivariate monomials, 
contains a multilinear term if and only if the original 
$k$-3D matching instance can be answered in the positive. 
We confirm by a simple example. 

For an instance with $A = \{a_1, a_2\}$, $B = \{b_1, b_2\}$, $C = \{c_1, c_2,
c_3\}$ and 
\[
  T = \{(a_1, b_1, c_1), (a_1, b_2, c_2), (a_2, b_2, c_3)\}
\]
(see Figure \ref{fig:3D_matching}), 
we have $P_1 = a_1b_1c_1 + a_1b_2c_2 + a_2b_2c_3$. For $k=2$, we get 
\begin{align*}
  P_2 &= (a_1b_1c_1 + a_1b_2c_2 + a_2b_2c_3)^2 \\
  &= a_1^2b_1^2c_1^2 + a_1^2b_2^2c_2^2 + a_2^2b_2^2c_3^2 + 
  2a_1^2b_1b_2c_1c_2 + 2a_1a_2b_1b_2c_1c_3 + 2 a_1a_2b_2^2c_2c_3.
\end{align*}
We may see that the multilinear monomial $2a_1a_2b_1b_2c_1c_3$ corresponds 
to a solution to our problem: the triples $(a_1,b_1,c_1)$ and $(a_2,b_2,c_3)$ are 
indeed disjoint, as seen in Figure \ref{fig:3D_matching}.
%
\begin{figure}[h]
  \includegraphics[width=0.3\textwidth, height=3.7cm]{3D_matching.png}
  \centering
  \caption{An example instance of $k$-3D matching, with inputs defined 
  as above. 
  TODO: change from edges to bubbles or something similar without relying on colors.}
  \label{fig:3D_matching}
\end{figure}
%\amnote{TeX-internal tool for diagrams: TikZ}

Thus, we have succesfully recuded a combinatorial problem to an 
algebraic one that is multilinear monomial detection. 
Note that in the scope of this thesis, we 
are indeed satisfied by merely \emph{detecting} a solution, i.e., deciding whether 
the underlying problem has a solution (although we briefly overview 
actually finding a solution in \Cref{sect:finding_the_solution}).

\subsection{Detecting a multilinear monomial}
\label{sect:problem_definition}

We have now reached multilinear monomial detection from the perspective 
of combinatorial problems. Furthermore, we may reach this point from 
\emph{parameterized} problems as well; instead of picking $k$ triples or edges, 
we may pick, say, $k-3$ combinations by only computing $P_{k-3}$ instead of $P_k$. 
Thus, the multilinear monomial detection approach works well with parameterization. 
The general, parameterized multilinear monomial detection problem is defined as follows: 

\begin{problem}
  \problemtitle{$k$-\textsc{multilinear monomial detection}}
  \probleminput{A polynomial $P_1 \in \Z[X]$ with the solution candidates encoded as monomials.}
  \problemquestion{Does the polynomial $P_k = P_1^k$ extended as a sum of monomials 
  contain a multilinear monomial of degree $k$?
  \footnote{a multilinear monomial with degree $k$ has $k$ indeterminates, 
  see also \Cref{sect:prelims_algebra}}}
\end{problem}

Clearly, an upper bound for solving the problem is given by a 
naive expansion of $P_1^k$ into a sum of monomials and scanning all the terms. 
However, this is not optimal: an $N$-degree polynomial will have $e^N$ 
possible monomials
\footnote{$e^N$ is an approximation from $\binom{n+N}{N}$, where $n$ is the number of variables}, 
and most problems using this algebrization 
(see \Cref{sect:related_problems}) 
have been solved with faster algorithms. 
This motivates the detection of multilinear monomials 
without fully expanding $P_k$ into a sum of monomials.

Since only multilinear terms are important in $P_k$, 
any squared variable can be instantly discarded as 
soon as it is formed 
during the computation of $P_1^k$. 
This can be achieved with dynamic programming 
to create a polynomial $P'_k$ that 
only contains multilinear monomials. 
Since there are $2^n$ multilinear monomials given $n$ variables, 
this method results in a slightly 
faster algorithm than with naive expansion.

However, the underlying problems are usually FPT 
(\emph{fixed-parameter tractable}, i.e., 
solvable in time polynomial to $n$ if $k$ is fixed). 
This implies that scaling exponentially 
with the number of variables is far from optimal. 
In order for the complexity of the algorithm to scale 
with the parameter $k$, we can reduce the number of variables 
by mapping $\rho \colon X \to Y$, where 
$\abs{X} \geq \abs{Y}$ and $\abs{Y} =$ \bigTheta{k}, 
and dynamically expand $(P'_1)^k \in \Z[Y]$ instead of
$P_k$, where $P'_1 \in \Z[Y]$ represents
\footnote{in algebraic terms, $P_1' = \Phi_\rho(P_1) \in \Z[Y]$ and $\Phi_\rho$ is
the canonical extension of $\rho$ to a ring homomorphism $\Z[X] \to \Z[Y]$}. 
$P_1 \in \Z[X]$ with every $x \in X$ replaced with $\rho(x)$

However, since $\abs{X} \geq \abs{Y}$, 
a multilinear monomial in $P_k$ may not be multilinear in $P'_k$ since 
we may map two different variables of a multilinear monomial in $X$ 
to the same variable in $Y$. 
For an algorithm to reliably detect a multilinear monomial, 
it is necessary to use different mappings 
from $X$ into $Y$ until a multilinear monomial survives the mapping. 
However, the probability that any given 
multilinear monomial survives a uniformly chosen random mapping
is around $e^{-\abs{Y}}$ \cite{KouWil15}. 
This implies that 
\bigOmega{e^{\abs{Y}}} random mappings must be tried for a 
multilinear monomial to survive with a reasonable constant probability. Thus, a 
$k$-multilinear monomial is detected with a 
randomized algorithm in \bigOstar{(2e)^{\abs{Y}}} time, where $\abs{Y} =$ \bigTheta{k}.

This is essentially the idea behind color coding 
introduced by \textcite{Alon95}. 
Although here given in this algebraic form for 
the $k$-multilinear monomial detection, 
color coding is purely combinatorial, 
and does not rely on algebraic techniques. 
However, since $k$-multilinear monomial detection is a 
purely algebraic problem, it is reasonable to 
conjecture that there is an algebraic method for solving it.

Indeed, a faster algebraic method exists; the technique of algebraic fingerprinting 
first introduced by \textcite{Koutis08} and 
further developed by \textcite{Williams09} 
solves $k$-multilinear monomial detection in \bigOstar{2^k} time. 
Since the technique focuses on the abstract $k$-multilinear monomial detection, 
to which many parameterized problems can be reduced to, 
it gives a general framework for 
solving parameterized problems \cite{KouWil15}.

\subsection{Related problems}
\label{sect:related_problems}

The importance of multilinear monomial detection lies in the fact 
that many parameterized combinatorial problems, as we see in this section, 
can be reduced to instances of it. 
Thus, there is great interest in efficiently solving the 
general $k$-multilinear monomial detection problem. 
Currently, the technique of algebraic fingerprints underlies the fastest algorithms 
for all the problems mentioned here. 
Note that only time complexity is discussed here. 
%However, though omitted, space complexities have also been improved with algebraic fingerprinting.

\citeauthor{Koutis08} was the first one to introduce and apply multilinear monomial 
detection for combinatorial problems, namely the \emph{$k$-path} and \emph{$m$-set $k$-packing} problems 
\cite{Koutis08}. 
In their work \cite{KouWil09}, \citeauthor{KouWil09} reduced 
the \emph{$k$-tree}, \emph{$k$-leaf spanning tree}, and \emph{$t$-dominating set} problems 
to $k$-multilinear monomial detection, and 
gave \bigOstar{2^k} algorithms for these problems.  

\textcite{Björklund16} showed reductions for the 
\emph{$k$-sized graph motif} problem and for
several optimization variants such as \emph{closest graph motif} 
and \emph{maximum graph motif} problems which are relevant in e.g. bioinformatics. 
\textcite{Cadena17} 
applied algebraic fingerprinting to general \emph{graph scan statistics} 
which is a methodology that detects anomalies in a graph. This is relevant in 
general network design problems and e.g. social network analysis.

\section{Preliminaries}
\label{sect:prelims}

It is necessary to recall basic algebraic concepts and common notation 
before further discussing multilinear monomial detection and algebraic fingerprinting. 
\Cref{sect:prelims_algebra} gives definitions for some necessary algebraic structures 
and concepts. \Cref{sect:prelims_circuits} gives a brief cover on arithmetic circuits. 

Some lesser-known notation is also used. FPT or \emph{fixed-parameter tractable} 
is a class of parameterized problems that 
can be solved in polynomial time if the parameter is fixed. 
\poly($n$) refers to a polymial function in $n$. 
$\mathcal O$* hides factors polynomial to the input size, e.g., 
\bigO{n^3k^n} = \bigOstar{k^n}.

\subsection{Algebra} 
\label{sect:prelims_algebra}

We generally refer to the following algebraic objects 
as \emph{algebraic structures}, i.e., objects that contain a 
set of elements and operations on these elements.

\textbf{Groups.} A \emph{group} $\mathbf G$
is a tuple $(G, +)$, where $G$ is a set of elements, 
$+ \colon G \times G \to G$ 
is a binary operation closed under 
the elements in $G$, $+$ is associative, every element $g \in G$ 
has an inverse $g^{-1}\in G$, and $G$ contains 
an identity element $e$ such that $g + e = g$, $g + g^{-1} = e$ and $e = e^{-1}$. 
Moreover, $\mathbf G$ is called \emph{Abelian} if 
$+$ is also commutative. A group is called \emph{multiplicative} if the operation 
is written as multiplication.

\textbf{Rings.} A \emph{ring} $\mathbf R$ is a triple $(R,+,\cdot)$, 
where $(R, +)$ is an Abelian group, and $\cdot \colon R \times R \to R$ 
is a binary operation closed under $R$. We call the binary operations $+$ and $\cdot$ 
addition and multiplication, respectively. A \emph{commutative ring} has commutative multiplication. 

Note, from here on we may use a bold typeface to represent either the set of elements 
or the algebraic structure itself, i.e., 
we may use expressions such as $u \in \mathbf{R}$, where $\mathbf{R} = (R,+,\cdot)$ and $u \in R$. 
Moreover, multiplication may be denoted by juxtaposition for brevity: $a \cdot b = ab$. 
Furthermore, we use coefficients and exponents in $\N$ to denote repeated operations of 
addition and multiplication, respectively: $a+a = 2a, \: a \cdot a=a^2$.

$\mathbf{R}$ must contain a multiplicative identity 
$\mathbf{1} \in \mathbf{R}$ such that $\forall a \in \mathbf{R} \colon a \cdot \mathbf{1} = a$. 
We notate the additive identity $e$ 
as $\mathbf{0}$ from here on. 
Observe that for any $R \neq \{\mathbf{0}\}$, $\mathbf{1} \neq \mathbf{0}$. 
Left and right distributive laws hold for rings, i.e., 
\[
  \forall a, b, c \in \mathbf{R} \colon a \cdot (b + c) = (ab) + (ac) \land (b + c) \cdot a = (ba) + (ca).
\]
$u \in \mathbf{R}$ is called \emph{unit} if it holds 
that $\exists v \in \mathbf{R} \colon uv = vu = \mathbf{1}$, 
i.e., it has a multiplicative inverse $v \in \mathbf{R}$.

\textbf{Fields.} A \emph{field} $\mathbf{F} = (F, +, \cdot)$ is defined by the following conditions:
\begin{itemize}
  \item $(F, +)$ is an Abelian group
  \item $(F\setminus \{\mathbf{0}\}, \cdot )$ is an Abelian group
  \item Left and right distributive laws hold for $\mathbf{F}$.
\end{itemize}

Equivalently, a ring is a field if every non-zero element is unit, $\mathbf{1} \neq \mathbf{0}$, 
and multiplication is commutative. 
The \emph{characteristic} of a field $\mathbf{F}$ is defined as follows:
\begin{equation}
  \texttt{char}(\mathbf{F}) =
    \begin{cases}
      \min\{n \in \N \colon n\mathbf{1} = \mathbf{0} \}\\
      0 & \text{if such $n$ does not exist}\\
    \end{cases}       
\end{equation}

Note that a field $\mathbf{F}$ with 
characteristic 2 satisfies the following:
\[
  \forall u \in \mathbf{F} \colon u + u = u \cdot (\mathbf 1 + \mathbf 1) = u \cdot \mathbf 0 = \mathbf 0
\]
Throughout the thesis we may use language such as \emph{cancelation due to characteristic} to 
refer to the fact that an element $f \in \mathbf{F}$ may cancel itself out in an expression if 
$\mathbf{F}$ has non-zero characteristic. 
We mainly use characteristic 2 in this thesis, and thus, we may say that 
$f$ cancels out due to characteristic when 
it has an even coefficient: $\forall k \in \N$, $2kf = k(2f) = k\mathbf{0}=\mathbf{0}$

Characteristics are prevalent in \emph{finite fields}, where the set of elements is finite. 
A simple example of a finite field is $\Z_2 = (\{\mathbf{0}, \mathbf{1}\}, +, \cdot)$, where 
the operations are standard addition modulo 2, and standard multiplication. 

Finite fields can be noted as $GF(p)$, called \emph{Galois fields}, where the field is unique 
up to \emph{isomorphism} if $p$ is a prime or a power of some prime. 
An isomorphism $\kappa \colon \mathbf{A} \to \mathbf{B}$ 
is a bijective mapping that satisfies 
$\forall u,v \in \mathbf{A} \colon \kappa(uv) = \kappa(u)\kappa(v) \wedge \kappa(u+v) = \kappa(u)+\kappa(v).$ 
Thus, if we only care for the relations between the elements, 
we may say that two isomorphic algebraic structures 
(i.e., there exists an isomorphism between them) 
are equivalent for us. 
Note that if $p$ is prime and $k \in \N$, the characteristic of $GF(p^k)$ is $p$. 
%Moreover, the non-zero elements of a finite field form a multiplicative group.

\textbf{Polynomial rings and multilinearity.} 
For a finite set $X$, 
A \emph{polynomial ring} in $X$, noted as $\mathbf{K}[X]$,
is a ring of polynomials with indeterminates (or variables) from $X$ and 
coefficients from the commutative ring $\mathbf{K}$. 
In this thesis, we only handle \emph{multivariate} 
polynomials, i.e., polynomials that have $\abs{X} = n > 1$. 

A \emph{monomial} in $X$ is of the form 
$X_1^{a_1}X_2^{a_2}\cdots X_n^{a_n}$, where $X_i \in X$ and $a_i \in \N$ marks the exponent. 
A monomial is \emph{multilinear} if 
$\forall i \in \{1, \ldots, n\} \colon a_i = 0 \vee a_i = 1$. 
A $k$-multilinear monomial has $k$ indeterminates. 
The \emph{degree} of a monomial $m$ 
is the sum of the exponents: $\deg(m) = \sum_{i=1}^n a_i$. 
Any element $P$ of such polynomial ring is a finite linear combination of these monomials 
with coefficients $c \in \mathbf{K}$: 
%\[
%  P = \displaystyle \sum_p k_p(X_1^{a_{1,p}} \cdots X_n^{a_{n,p}})
%\] 
\[
  P = \sum_{p_1,\dots,p_n \ge 0} c_{p_1,\dots,p_n} X_1^{a_{p_1}} \cdots X_n^{a_{p_n}}
\] 

If a polynomial is in such form, we may say that it is in \emph{sum of monomials form}.

Alternatively, a polynomial ring $\mathbf{K}[X]$ can be thought of as a vector
space over $\mathbf{K}$ of infinite dimension with 
the set of all monomials in $X$ as a basis. 
Polynomial rings have three operations: addition, multiplication 
and scalar multiplication. In terms of vectors, addition and scalar multiplication follow 
the standard addition and scalar multiplication for vectors. 
Note that the scalar value must be in $\mathbf{K}$. 
The multiplication is defined as follows: 
let $M(X)$ denote the set of all monomials in $X$, and 
$P_d$ denote a polynomial in $\mathbf{K}[X]$ of the form $P_d = \sum_{m \in M(X)} d_m m$, 
where $d_m \in \mathbf{K}$. Then, 
\[
  \forall P_a,P_b \in \mathbf{K}[X] \colon P_a \cdot P_b
  = \left( \sum_{m \in M(X)} a_m m\right)
  \cdot \left(\displaystyle \sum_{n \in M(X)} b_n n\right) = \displaystyle \sum_{m,n \in M(X)} (a_mb_n) (mn)
\]
Note that the definition for the coefficient $c_m$ essentially 
decides whether a monomial $m \in M(X)$ appears in a polynomial. If a polynomial $P$ 
does not contain the monomial $g$, then it must be that $c_g = \mathbf{0} \in \mathbf{K}$.

\emph{Evaluation of a polynomial} $P$ at $Z$ is denoted $P(Z)$, where 
$Z$ is a map $X \to \mathbf{R}$ and $\mathbf{R}$ is a ring containing $\mathbf{K}$. 
Evaluating at $Z$, i.e., assigning indeterminates $X$ to $R$, defines an 
element from the ring $\mathbf{R}$, as $P(Z) \in \mathbf{R}$. We may note the unevaluated 
polynomial as $P(X)$ to highlight the set of indeterminates. 
A polynomial is identical to $\mathbf{0}$, or \emph{identically 
evaluates} to $\mathbf{0}$, if for every mapping $W \colon X \to \mathbf{R}$ $P(W) = \mathbf{0}$.

In this thesis, we mainly use elements of \emph{group algebras} 
for evaluation, i.e., $\mathbf{R} = \mathbf{K}[\mathbf{G}]$, where $\mathbf{G}$ is a 
multiplicative group.

\textbf{Group algebras.} A group algebra is an algebraic structure 
very similar to a polynomial ring, and 
is also noted as $\mathbf{R}[\mathbf{G}]$, where $\mathbf{R}$ is a commutative ring and 
$\mathbf{G}$ is a multiplicative group. A group algebra may be thought of as a 
polynomial ring $\mathbf{R}[X]$, where the indeterminates $X$ form a multiplicative group $\mathbf{G}$. 
The elements and operations in a group algebra have the same form as those in a polynomial ring, 
with the exception that instead of summing over monomials in $X$, 
we sum over the elements of $\mathbf{G}$.

Note that $\mathbf{0} \in \mathbf{R}[\mathbf{G}]$ corresponds to a 
polynomial $P \in \mathbf{R}[\mathbf{G}]$ with zero-coefficients, and 
$\mathbf{1} \in \mathbf{R}[\mathbf{G}]$ corresponds to the identity element of $\mathbf{G}$. 

\subsection{Arithmetic circuits}
\label{sect:prelims_circuits}

Computing arithmetic expressions such as polynomial evaluations 
can be represented by \emph{arithmetic circuits}, that is, 
connected acyclic directed graphs, where terminal vertices correspond to initial and output values, 
and other vertices correspond to \emph{arithmetic gates}, i.e., arithmetic operations. 

In this thesis, we consider \emph{addition} and \emph{multiplication} gates. 
These gates correspond to the binary operations of the underlying algebraic structure 
which the arithmetic expression is evaluated over and given initial values from. Thus, 
the addition and multiplication gates may have \emph{fan-in two} and \emph{fan-out one}, 
i.e., each gate-vertex has three edges connected to it: two as an input, and one as an output. 
If the underlying algebra is commutative, we may call the arithmetic circuit a \emph{commutative circuit}. 
%However, since we are using mainly commutative algebras in this thesis, we may define the 
%gates for binary operations to have unbounded fan-in. 

For example, an abstract evaluation of a polynomial $P \in \Z[a,b,c,d]$ of the form 
$P = (ab+cd)^2$ is given by the arithmetic circuit presented in Figure \ref{fig:circuit_example}. 
Note that we use the same symbols for addition and multiplication gates as seen in the figure 
in all arithmetic circuit diagrams in this thesis. 
Note that in \Cref{sect:fingerprints}, we augment a circuit with \emph{scalar multiplication}, 
though we denote them with standard multiplication gates.

\begin{figure}[h]
  \includegraphics[width=0.7\textwidth, height=5.9cm]{arithmetic_circuit_EXAMPLE.png}
  \centering
  \caption{A circuit for evaluating $(ab+cd)^2$. 
  Note that the input terminals have been copied for clarity.}
  \label{fig:circuit_example}
\end{figure}

%\clearpage
\section{General multilinear monomial detection}
\label{sect:general_mld}

The detection of multilinear monomials in a multivariate polynomial is a fundamental problem, 
since many important problems can be reduced to it, 
as seen in \Cref{sect:related_problems}. 
Therefore, any progress in general multilinear monomial detection implies 
faster algorithms for the problems mentioned in \Cref{sect:related_problems}.

In this section, 
we discuss the algebraic ideas by \citeauthor{KouWil09} \cite{Koutis08, Williams09, KouWil09} 
for the $k$-multilinear monomial detection. 
In \Cref{sect:algebraic_fingerprinting}, 
we dive into the technique of \emph{algebraic fingerprinting}, and 
see the ideas and implementation of \textcite{Koutis08}. 
\Cref{sect:polynomial_identity_testing} covers how 
\textcite{Williams09} developed this idea  
in the perspective of polynomial identity testing. 
In \Cref{sect:complexity} we briefly discuss the time and space complexity 
of the general algebraic framework given by algebraic fingerprinting. 
Finally, \Cref{sect:limits} discusses the limits of algebraic fingerprinting.

As a prelude for the following sections, recall the relevant problem definition: 
\begin{problem}
  \problemtitle{$k$-\textsc{multilinear monomial detection}}
  \probleminput{A commutative arithmetic circuit $A$ representing a polynomial $P(X)$.}
  \problemquestion{Does the polynomial $P(X)$ extended as a sum of monomials 
  contain a multilinear monomial of degree $k$?}
\end{problem}

\subsection{Algebraic fingerprinting}
\label{sect:algebraic_fingerprinting}

In \Cref{sect:problem_definition}, we discussed non-algebraic methods 
for approaching $k$-multilinear monomial detection. In particular, we mention
an interesting idea of discarding squared variables when dynamically 
computing the circuit. From this, we build towards algebraic fingerprinting. 

This idea of discarding squared variables as soon as they are formed in $A$ 
can be expressed mathematically: any squared variable should be identical to
zero. 
\begin{equation}
  \label{eq:squared_to_zero}
\forall x \in X: x^2 = \mathbf{0}
\end{equation}
This implies that any non-multilinear monomial in $X$ will evaluate to zero in $P(X)$, since 
any non-multilinear monomial $q$, assuming commutativity, can be written as $x^2q'$ 
for some $x \in X$, and $x^2q' = \mathbf{0}q' = \mathbf{0}$ over any algebra. 
Therefore, $P(X)$ will identically evaluate to zero if there are no multilinear monomials, 
i.e., there exist no solutions to the original problem.

This is the basis of algebraic multilinear monomial detection introduced by 
\textcite{Koutis08}, 
or later referred to as \emph{algebraic fingerprinting} \cite{KouWil15}: 
we evaluate $P(X)$ over some algebraic structure $\mathbf{G}$, 
and detect a multilinear monomial from 
the value returned by this evaluation. Ideally, with any 
chosen mapping $Z \colon X \to \mathbf{G}$ 
where $w \neq \mathbf{0}$, 
\begin{equation}
  \label{eq:polynomial_identity}
  P(Z) =
    \begin{cases}
      \mathbf{0} & \text{if no multilinear monomials exist}\\
      w & \text{otherwise}\\
    \end{cases}       
\end{equation}

In the following subsections, we specify an appropriate algebraic structure such that 
(\ref{eq:polynomial_identity}) is met, as well as some requirements for efficiency. 
Then, we discuss the works of \textcite{Koutis08}, 
and see how these specifications were implemented.

This thesis refers to the general framework provided 
by this algebraic technique for parameterized problems \cite{KouWil09, KouWil15} as 
algebraic fingerprinting. However, algebraic fingerprinting can also 
be used to refer specifically to the idea behind solving a problem 
with multilinear monomials canceling out due to characteristic,  
which is discussed in \Cref{sect:fingerprints}.

\subsubsection{Specifications for the algebraic structure}
\label{sect:algebra_specs}

We have arrived at an important task for multilinear monomial detection: 
find an appropriate algebraic structure $\mathbf{G}$ for 
the evaluation of $P$ over $\mathbf{G}$ to meet 
(\ref{eq:squared_to_zero}) and thus the first equality in (\ref{eq:polynomial_identity}). 
We specify for commutative algebraic structures such as 
commutative rings for multilinear monomial detection; 
$\mathbf{G}$ should have commutative multiplication in order for (\ref{eq:squared_to_zero}) 
to be effective. The ordering of indeterminates in monomials is generally unknown, 
since the specific algebrization into multilinear monomial detection 
is abstracted away. %Specifying for commutativity also makes it significantly 
%easier to algebrize problems into arithmetic circuits. 

For the second equality in (\ref{eq:polynomial_identity}), it is necessary that multilinear 
monomials in $P(X)$ are not identical to $\mathbf{0}$ over $\mathbf{G}$. 
More specifically, 
$w$ should not be identical to $\mathbf{0}$. 
Thus, it must be that $k \leq \abs{\mathbf{G}}$, where $k$ is the degree of the monomials. 
Although this is not enough to ensure that $w \neq \mathbf{0}$ (as seen in the following section), 
we leave the issue for now.

These are the necessary specifications for $\mathbf{G}$ for algebraic multilinear monomial detection. 
However, this algebraic detection must be efficient for it to be useful. 
Therefore, further requirements are necessary: (a) the binary operations of $\mathbf{G}$ 
must be efficiently computable 
for a fast evaluation of $P(X)$, and (b) multilinear monomials in $P(X)$ must 
survive the evaluation of $P$ under an assignment $\gamma \colon X \to \mathbf{G}$ 
with a constant positive probability. We reason the 
sudden appearance of \emph{survivability} and probabilities soon.

Recall from \Cref{sect:problem_definition} 
that with color coding, multilinear monomials can be detected with a 
randomized algorithm in \bigOstar{(2e)^k} time. Thus for (a), we may specify for 
an evaluation of $P(X)$ to take \bigOstar{2^k} time. The polynomial $P(X)$ 
will have at most $2^k$ multilinear monomials. Therefore, 
it is necessary that the binary operations 
of $\mathbf{G}$ take polynomial time.

With (b), recall that multilinear monomials 
survive color coding with probability $e^{-k}$. 
With algebraic fingerprinting, although not identical to zero, a multilinear monomial in $P(X)$ 
can still evaluate to $\mathbf{0} \in \mathbf{G}$ under some assignment $\gamma \colon X \to \mathbf{G}$. 
However, if we specify for a constant 
probability of survival under random $\gamma$, we can reliably decide whether a multilinear monomial exists 
by evaluating $P(X)$ in $\mathbf{G}$ over a constant number of 
randomized assignments $X \to \mathbf{G}$. Relating to color coding, 
this would essentially remove the 
$e^k$ factor in \bigOstar{(2e)^k}.

To restate, we now have to find such a commutative ring $\mathbf{G}$ that 
meets the following specifications: 
\begin{itemize}
  \item $\forall g \in \mathbf{G} \colon g^2 = \mathbf{0}$
  \item Operating over $\mathbf{G}$ should be fast, i.e., evaluating 
  $P(X)$ should take \bigOstar{2^k} time.
  \item Multilinear monomials should evaluate to non-zero
  through a random assignment 
  $\gamma \colon X \to \mathbf{G}$ with constant positive probability.
\end{itemize}

In the work that introduced 
this algebraic fingerprinting technique \cite{Koutis08}, 
\citeauthor{Koutis08} used the group algebra $\Z_2[\Z_2^k]$. 
\citeauthor{Williams09} developed the technique further, 
generalizing the algebra to $GF(2^{l})[\Z_2^k]$ \cite{Williams09}. 
Next, we look at these group algebras of $\Z_2^k$ for $\mathbf{G}$, 
although the ideas of \citeauthor{Williams09} are discussed only 
later in \Cref{sect:polynomial_identity_testing}.

\subsubsection{Using group algebras of $\Z_2^k$}

The multiplicative group $\Z_2^k$ consists of $k$-dimensional \{0,1\}-vectors 
with the binary operation defined as component-wise addition modulo 2. 
For example with $k = 3$, 
\[
  \begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix} \cdot 
  \begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix} =
  \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix} = \mathbf{0} \in \Z_2^3.
\]
Observe that in general, every element in $\Z_2^k$ is its own inverse:
\begin{equation}
  \label{eq:Z_2^k has char 2}
  \forall z \in \Z_2^k \colon z^2 = \mathbf{0}.
\end{equation}
Recall that the elements of a group algebra 
$\mathbf{F}[\Z_2^k]$ are linear combinations of the form 
\[
  \displaystyle \sum_{v \in \Z_2^k}a_v v,
\]
where $a_v \in \mathbf{F}$. From here on, we note the identity of $\Z_2^k$ as $v_0$, additive and 
multiplicative identities of $\mathbf{F}$ as $\mathbf{0}_F$ and $\mathbf{1}_F$, respectively, and 
use $\mathbf{0}$ and $\mathbf{1}$ for the identities of 
$\mathbf{F}[\Z_2^k]$. Recall that $\mathbf{1} = v_0$, and
$\mathbf{0}$ corresponds to the element $\sum_{v \in \Z_2^k}a_v v$, where $a_v =
\mathbf{0}_F$. Note that + represents addition over $\mathbf{F}[\Z_2^k]$ and not 
addition over $\Z_2^k$ which is a multiplicative group.

In his introductory work for this technique \cite{Koutis08}, 
\citeauthor{Koutis08} assigned $X$ 
to elements of the form $(v_0 + v_i) \in \mathbf{F}[\Z_2^k]$, 
such that for every $x_i \in X$, a random $v_i \in \Z_2^k$ is independently and uniformly 
picked for the assignment 
$\gamma(x_i) = v_0 + v_i$. %{$x_i \to (v_0 + v_i)$.} 
We note the mapping as $\gamma$, and the resulting element  
from the polynomial evaluation 
as $P(\gamma) \in \mathbf{F}[\Z_2^k]$. 
\citeauthor{Koutis08} observed that 
due to (\ref{eq:Z_2^k has char 2}), for all $v \in \Z_2^k$ and $(v_0 + v) \in \mathbf{F}[\Z_2^k]$, 
\[
  (v_0 + v)^2 = v_0^2 + v_0v + vv_0 + v^2 = v_0 + v + v + v_0 = 2v_0 + 2v.
\]
This implies that if we pick a field with characteristic 2 for $\mathbf{F}$, 
$\forall v_i \in \Z_2^k \colon (v_0 + v_i)^2 = \mathbf{0}$. Thus, 
non-multilinear monomials in $P(X)$ vanish in $P(\gamma)$, and the 
first equation in (\ref{eq:polynomial_identity}) 
will hold.

However, the second equation of (\ref{eq:polynomial_identity}) 
does not necessarily hold, and it may be that $w = \mathbf{0}$. 
A multilinear monomial may evaluate to zero if two variables  
are assigned the same value from $\mathbf{F}[\Z_2^k]$. 
This itself is not too concerning here: 
a monomial $X_1 \cdots X_k$ assigned to be the product 
$(v_0 + v_1) \cdots (v_0 + v_k)$ survives this uniform random assignment, i.e. 
evaluates to non-zero, with probability at least $1/4$ \cite{Koutis08}.

Since $\mathbf{F}$ has characteristic 2 however, 
multilinear monomials may still cancel each other out 
in $\mathbf{F}[Z_2^k]$ if they have even leading 
coefficients in $P(X)$. In such case, multilinear monomials do not 
survive under any assignment $X \to \mathbf{F}[\Z_2^k]$. 
Next, we see how \citeauthor{Koutis08} approached this problem.

\subsubsection{Fingerprints to prevent unwanted cancelation}
\label{sect:fingerprints}

Indeed, if we take the $k$-3D matching instance from Section \ref{sect:algebrization}, 
we notice that the multilinear monomials in $P_2$ have even coefficients, and thus 
would cancel out in $\mathbf{F}[Z_2^k]$ due to characteristic.
\begin{align*}
  P_2 &= (a_1b_1c_1 + a_1b_2c_2 + a_2b_2c_3)^2  \\
  &= a_1^2b_1^2c_1^2 + a_1^2b_2^2c_2^2 + a_2^2b_2^2c_3^2 + 
  2a_1^2b_1b_2c_1c_2 + 2a_1a_2b_1b_2c_1c_3 + 2 a_1a_2b_2^2c_2c_3. 
\end{align*}
In general, when $k$ is even, multilinear monomials will have even coefficients. 

To tackle this issue, one idea is to add auxiliary indeterminates, 
called \emph{fingerprints} \cite{KouWil15}, to the monomials 
in order to make them unique. For example, let $S = \{s_1, \ldots, s_6\}$ 
be the set of an appropriate number of fingerprints 
and augment them to $P_k$ as follows: 
\begin{align*}
  P'_2 = &\:(s_1a_1b_1c_1 + s_2a_1b_2c_2 + s_3a_2b_2c_3)(s_4a_1b_1c_1 + s_5a_1b_2c_2 + s_6a_2b_2c_3) \\
  = &\:s_1s_4a_1^2b_1^2c_1^2 + s_2s_5a_1^2b_2^2c_2^2 + s_3s_6a_2^2b_2^2c_3^2 \: \\
  &\:+s_1s_5a_1^2b_1b_2c_1c_2 + s_2s_4a_1^2b_1b_2c_1c_2 + s_1s_6a_1a_2b_1b_2c_1c_3 \: \\
  &\:+s_3s_4a_1a_2b_1b_2c_1c_3 + s_2s_6a_1a_2b_2^2c_2c_3 + s_3s_5a_1a_2b_2^2c_2c_3. 
\end{align*}

Then, the multilinear monomial detection algorithm 
could assign every $a \in X \cup S$ to $\mathbf{F}[\Z_2^k]$. 
With this, non-multilinear monomials will still vanish, but multilinear monomials 
will not \emph{identically} cancel each other out when $k$ is even. 

However, introducing new indeterminates raises the degree of multilinear
monomials. 
Therefore, it increases the probability that indeterminates in a multilinear monomial are 
assigned the same value from $\mathbf{F}[Z_2^k]$, which results in the 
multilinear monomial evaluating to zero with higher probability. 
This can be countered by increasing the number of elements to assign to, i.e., 
increasing the number of distinct elements of form $(v_0 + v_i) \in \mathbf{F}[Z_2^k]$. 
Counteractively raising the dimension of $\Z_2^k$, however, would 
exponentially slow down matrix multiplications which prove to be %matrix mulitplication has a time complexity of \bigO{n^2.31788} \cite{DuanZhouWu22}. 
important for efficiency in algebraic fingerprinting (see \Cref{sect:complexity}).

\citeauthor{Koutis08} approached this problem by assigning fingerprints to elements 
from a different algebraic structure: he used $S \to \Z_2$ and set 
$\mathbf{F} = \Z_2$ \cite{Koutis08}. In this sense, 
fingerprints are defined to be auxiliary coefficients instead of auxiliary indeterminates. 
Note that $\Z_2$ has characteristic 2. With this, 
\citeauthor{Koutis08} essentially assigns multilinear monomials a coefficient 
randomly from $\{\mathbf{0}_F, \mathbf{1}_F\}$. The idea is that a multilinear monomial, 
assigned with the fingerprint $\mathbf{1}_F$,  
survives the cancelation due to characteristic if the canceling pair is assigned $\mathbf{0}_F$. 
With randomized assignments $S \to \Z_2$, 
there is a constant positive probability that a multilinear 
monomial will have an odd coefficient, and thus survive the assignment \cite{Koutis08}.

In practice, fingerprints can be implemented 
into the algebrization as follows (see also Figure \ref{fig:circuit_fingerprints}): 
for every multiplication gate $G_i$ feeding into an addition gate 
in the arithmetic circuit $A$ for $P(X)$, 
pick a unique $s_i \in S$. Insert a new multiplication gate $\overbar{G_i}$ that takes 
as input $s_i$ and the output of $G_i$. The output of $\overbar{G_i}$ feeds to the 
gates that read the output of $G_i$. We note the new polynomial represented by this circuit 
as $P'(X, S)$. Note that here 
\citeauthor{Koutis08} picked random elements from $\Z_2$ for $s_i$.

\begin{figure}[h]
  \includegraphics[width=\textwidth, height=7cm]{arithmetic_circuit_FINGERPRINTS.png}
  \centering
  \caption{A fingerprinted circuit for evaluating $(ab+cd)^2$. 
  Note the added terminals on the right circuit.}
  \label{fig:circuit_fingerprints}
\end{figure}

\subsection{Polynomial identity testing}
\label{sect:polynomial_identity_testing}

From another perspective, we may look at algebraic fingerprinting as \emph{polynomial identity testing}. 
That is, we compute $P'(X, S)$ over assignments 
$\overbar{X} \colon X \to \mathbf{F}[\Z_2^k]$ into $P'(\overbar{X}, S)$, i.e., 
compute until the gates $\overbar{G_i}$. 
Imagine we stop here in the circuit before assigning the fingerprints $S$ 
and continuing with the multiplication. 
Currently, we may see $P'(\overbar{X}, S) \in \mathbf{K}[S]$ as a polynomial 
with indeterminates from $S$ and coefficients from $\mathbf{K} = \mathbf{F}[\Z_2^k]$. 
In a sense, we switch the roles of coefficients and indeterminates in $P'(X, S)$ 
to find a new polynomial $Q(S) \in \mathbf{K}[S]$. 

Now, deciding whether a multilinear monomial exists in $P(X)$ is essentially given by 
whether the polynomial $P'(\overbar{X}, S) \in \mathbf{K}[S]$ is identical to $\mathbf{0}$, 
i.e., with $\Phi$ representing the family of mappings $S \to \mathbf{F}$, 
\[
  \forall \phi \in \Phi %, \overbar{S} = \{\phi(s) \: | \: s \in S\} 
  \colon P'(\overbar{X}, \phi) = \mathbf{0}.
\]
Therefore, we formulate algebraic fingerprinting as polynomial identity testing, i.e., 
we test whether $P'(\overbar{X}, S) \in \mathbf{K}[S]$ is identical to $\mathbf{0}$.

\begin{problem}
  \problemtitle{\textsc{Polynomial identity testing}}
  \probleminput{An arithmetic circuit $C$ that computes the polynomial $Q(S)$.}
  \problemquestion{Is $Q(S)$ identical to the zero polynomial?}
\end{problem}

We frame $P'(\overbar{X}, S)$ as $Q(S) \in \mathbf{K}[S]$. 
Here, it is necessary to test whether $Q(S)$ is identical to \emph{zero modulo 2}, 
since we used characteristic 2 to eliminate 
the underlying non-multilinear monomials in $P'(\overbar{X}, S)$.

Thus, multilinear monomial detection is reduced via algebraic fingerprinting 
to polynomial identity testing. 
We note the family of assignments $S \to \mathbf{F}$ as $\Phi$. 
A multilinear monomial is detected if 
$\exists f \in \Phi \colon Q(f) \neq \mathbf{0}_F \in \mathbf{F}$, 
where $\mathbf{F}$ is a field of characteristic 2. 
Polynomial identity testing is a well-studied problem, and can be efficiently 
solved with random test evaluations by the \emph{Schwartz-Zippel Lemma} \cite{Saxena09}. 
Essentially, the lemma gives an upper bound for the probability of false-negatives 
and, subsequently, the number of necessary random test evaluations 
for a satisfactory result on polynomial identity.

\newtheorem*{lemmaSZ}{Schwartz-Zippel Lemma}
\begin{lemmaSZ}
  Let $P \in F[X]$ be a non-zero polynomial of degree $d$ over a field $F$. 
  Let $Z$ be a uniformly chosen random mapping $Z \colon X \to F$. Then, 
  \[ 
    \Pr[P(Z) = \mathbf{0}] \leq \frac{d}{\abs{F}}.  
  \]
\end{lemmaSZ}

Assume multilinear monomials exist in $P(X)$. 
\citeauthor{Koutis08} achieved to detect a multilinear monomial 
with a probability $(1/4 + 1/{4k})$ by testing whether 
$Q(S) = \mathbf{0}$ over the field $\mathbf{F} = \Z_2$  
with randomized assignments $S \to \Z_2$ \cite{Koutis08}. 
\citeauthor{Williams09} developed the technique of algebraic fingerprinting 
further by observing that due to the Schwartz-Zippel Lemma, %(see \cref{sect:prelims}), 
if we raise the order of the field $\mathbf{F}$ 
such that the number of different assignments in $\Phi$ is much larger than 
the number of assignments $\phi \in \Phi$ that have $Q(\phi) = \mathbf{0}_F$, 
$Q(\delta) \neq \mathbf{0}_F$ with a high probability over an arbitrary $\delta \in \Phi$ 
\cite{Williams09}. 

Of course, $\mathbf{F}$ must have characteristic 2. For this, \citeauthor{Williams09} 
used the field $GF(2^{l})$ with $l \in \N$ \cite{Williams09}. By Schwartz-Zippel, $Q(S)$ 
evaluates to $\mathbf{0}_F$ over a random assignment $S \to GF(2^{l})$ with probability 
at most $k/{2^l}$. With the $k$-path problem, for instance, \citeauthor{Williams09} used $l = 3 + \log_2k$, 
which sets the probability of a false-negative evaluation 
to at most $1/2^3$. Note that unlike with $\Z_2$, 
we do not need the additive identity here, 
and we can assign fingerprints to values of $GF(2^{l}) \setminus \{\mathbf{0}\}$.

For $k$-path, \citeauthor{Koutis08} 
gave a randomized \bigOstar{2^{3k/2}} time algorithm \cite{Koutis08}, 
and \citeauthor{Williams09} developed this into a randomized \bigOstar{2^k} 
time algorithm \cite{Williams09} with the ideas discussed here. 
Furthermore, \citeauthor{Williams09} 
generalized the technique by introducing the parameter $l$ for the Galois field.

\subsection{Time and space complexity}
\label{sect:complexity}

In the previous sections, we discussed the specifications 
for an algebraic stucture to implement algebraic fingerprinting. 
For an appropriate algebraic structure, we found $GF(2^{l})[Z_2^k]$. 
However, we did not discuss the costs related 
to this algebra. In this section, we briefly discuss the time and space complexity 
of algebraic fingerprinting.
%
%Define the evaluation of $P'(X, S)$ at any $X$ and $S$ to take $g(n)$ number of  
%arithmetic operations, where $n = \abs{X}$. In general, 
%detecting $k$-degree multilinear monomials in $P(X)$ takes 
%\bigOstar{2^kg} time and \bigO{poly(n,k)} space \cite{Williams09}.

Actually, the complexities given by \textcite{Koutis08} and 
\textcite{Williams09} did not directly come from 
$\Z_2[Z_2^k]$ or $GF(2^{l})[Z_2^k]$. 
To make the complexity claims in \cite{Koutis08}, 
\citeauthor{Koutis08} used a well-known \cite{Terras99} isomorphism 
$\kappa \colon \Z[\Z_2^k] \to \mathcal{M}$, where $\mathcal{M} = \mathbf{M}^{2^k \times 2^k}$ 
is an algebra of special permutation matrices with binary entries. To translate $\Z[\Z_2^k]$ to 
$\Z_2[\Z_2^k]$, it is enough to take the modulo 2 of the coefficients $a_v$ in 
the elements of $\Z[\Z_2^k]$: 
\[
  \sum_{v \in \Z_2^k}a_v v \in \Z[\Z_2^k] \implies 
  \sum_{v \in \Z_2^k}(a_v \bmod 2) v \in \Z_2[\Z_2^k]
\]

%Thus, if we assign $S$ to $\Z$, it is enough to consider the parity of 
%the coefficient of $v_0 \in \Z_2^k$ in $P_S(\overbar{X})$ \cite{Koutis08}. 
Since \citeauthor{Koutis08} 
used an isomorphism, all the ideas given in 
\Cref{sect:algebraic_fingerprinting} still hold for 
detecting multilinear monomials. That is, 
the given implementation for (\ref{eq:polynomial_identity}) 
is valid through $\kappa$.

Computing on these matrices, 
\textcite{Koutis08} detected $k$-multilinear monomials 
%by computing the \omnote*{add to prelims?}{trace} of the matrix resulting 
%from the evaluation of $P_S(X)$ over $\mathcal{M}$. The trace can be computed 
in time \bigO{2^k(nk+t)} and space \bigO{nk+s}, where $t$ and $s$ are the time 
and space complexity of the $g(n)$ arithmetic operations, respectively. 
For $GF(2^{l})[Z_2^k]$, the same ideas are used, though we omit 
further discussion into this for the sake of brevity. 
Thus, we have a general 
\bigOstar{2^k} time and \bigO{\poly(n,k)} space algorithm for detecting 
$k$-degree multilinear monomials in $P(X)$, where $n = \abs{X}$ \cite{KouWil09}.

It is important to note here that this complexity is for $k$-degree 
multilinear monomial detection. Whether a parameterized problem with a parameter 
$k$ receives an \bigOstar{2^k} time algorithm is determined by the algebrization 
of said parameterized problem. 
For instance with $k$-path, algebraic fingerprinting gives an \bigOstar{2^k} 
time algorithm \cite{Williams09}. 
For $k$-3D matching however, as given in \Cref{sect:algebrization}, 
algebraic fingerprinting gives an \bigOstar{2^{3k}} algorithm, since 
$k$-3D matching reduces into $3k$-degree multilinear monomial detection.

\section{Limits of algebraic fingerprinting}
\label{sect:limits}

In this section, we discuss some limiting factors to the general 
algebraic framework given by 
algebraic fingerprinting for parameterized problems. First, 
we discuss the lower bound for the runtime. Then, we discuss 
the difficulties for derandomization. Finally, we touch on the issue of 
\emph{finding} a solution for the underlying combinatorial problem 
whereas algebraic fingerprinting only detects that one exists.

\subsection{Algebraic optimization}
\label{sect:algebra_is_optimal}

In \Cref{sect:complexity}, it was established that $k$-multilinear monomials 
in $P(X)$ are detected with 
algebraic fingerprinting in \bigOstar{2^k} time. 
This time was achieved by evaluating the circuit over matrix 
representations of the group algebra $GF(2^l)[\Z_2^k]$.

%Furthermore, 
\citeauthor{KouWil09} showed that this particular algebra is nearly optimal 
for time complexity \cite{KouWil09}: there is no significantly faster algebra that 
is appropriate for the general $k$-multilinear monomial detection. 
The authors proved that if any commutative algebraic structure $\mathcal{G}$ is 
used for detecting $k$-multilinear monomials, 
the lengths of elements in $\mathcal{G}$ must be \bigOmega{2^k/k}.

Thus for the general $k$-multilinear monomial detection, we may say 
that algebraic fingerprinting is in some sense 
optimal, and cannot be improved upon. 
However, 
ideas from algebraic fingerprints can be utilized for faster algorithms for 
specific $k$-multilinear monomial detection instances (see \Cref{sect:improvements}).

\subsection{Derandomization}
\label{sect:derandomization}

Algebraic fingerprinting gives a randomized algorithm for $k$-multilinear monomial detection. 
The derandomization of the general framework seems hard since algebraic fingerprinting 
uses the fact that polynomial identity testing can be solved in polynomial time with 
a randomized algorithm \cite{Williams09}.

If algebraic fingerprinting can be derandomized 
in polynomial time, it implies that polynomial identity testing can be solved with a 
polynomial time deterministic algorithm. However, this
implies proving superpolynomial 
lower bounds for arithmetic circuit sizes, which is notoriously hard \cite{Kabanets03}. 
Therefore, with respect to the several decades of 
sustained effort directed at circuit lower bounds \cite{Kabanets03}, 
it seems unlikely that someone discovers a derandomization of polynomial identity testing 
in the near future.

Thus, finding a deterministic algorithm 
probably requires a different apporach from polynomial identity testing. 
Although this is mostly outside the scope of this thesis, 
in \Cref{sect:other_improvements} we briefly return to this discussion.

\subsection{Finding the solution}
\label{sect:finding_the_solution}

In many instances of multilinear monomial detection, 
a solution to the underlying problem can be directly found 
from the multilinear monomials by 
reverse-engineering the algebrization. 
However in algebraic fingerprinting, we do not have this information on the monomials: 
when we assign the variables values and evaluate the polynomial, we may only detect the 
presence of a solution. As such, algebraic fingerprinting applies to decision algorithms.

However, while constructing such a decision algorithm is generally hard for 
many combinatorial problems (e.g. problems in \Cref{sect:related_problems}), 
finding the solution using such an algorithm 
(i.e., constructing a \emph{search} algorithm) is often easy. 
For example, it is widely known that decision and search algorithms 
for NP-complete problems are essentially equivalent in complexities \cite{Bellare94}. 
Moreover, since most of the problems in \Cref{sect:related_problems} 
have search problems in FPT, it is known that a solution can be found in polynomial time when its 
existence can be detected efficiently.

For example, in \cite{Koutis08}, 
\citeauthor{Koutis08} gives an algorithm that detects a $k$-path, and shows that a 
$k$-path can be found by \bigOstar{n+\min(k^2, m)} applications of the given
algorithm, where $n$ is the number of vertices and $m$ the number of edges in the input graph. 
In general for subgraph problems, we may find a solution by calling the decision 
algorithm a polynomial number of times for different subgraphs of the original input graph.

%\clearpage
\section{Improving from algebraic fingerprinting}
\label{sect:improvements}

As mentioned in \Cref{sect:algebra_is_optimal}, 
algebraic fingerprinting as a framework 
for $k$-multilinear monomial detection has a lower bound of
\amnote*{$\Omega$ or $\Omega*$?}{\bigOmega{2^k}}. 
However, this framework is very generic since it 
approaches the abstracted multilinear monomial detection without 
utilizing the combinatorial properties specific to the underlying problem. 
Creative algebrizations, though, 
have potential for exploiting these properties.

Indeed, faster algorithms for specific combinatorial problems 
have been found by designing new algebrizations utilizing techniques 
similar to algebraic fingerprinting. In \Cref{sect:cancel_nonsolutions}, 
we see how \textcite{Björklund14} 
exploited the cancelation due to characteristic to cancel non-solution monomials 
\amnote*{?}{by clever design of algebrization}. 
For parameterized problems in general, 
\Cref{sect:other_improvements} 
briefly overviews other ideas and 
improvements in the domain of $k$-multilinear monomial detection.

\subsection{Fingerprinting for cancelation of non-solutions}
\label{sect:cancel_nonsolutions}

In the algebraic framework by \citeauthor{KouWil09}, 
characteristic 2 is essentially a by-product of implementing 
the idea of discarding squared variables, and fingerprints are merely 
introduced to prevent valid solutions from canceling out.

\textcite{Björklund14}, however, approached the elimination of 
non-solutions from a different angle: instead of focusing on squared elements, 
\citeauthor{Björklund14} focused on the coefficients, 
and used characteristic 2 to eliminate non-solutions by designing 
the algebrization such that non-solution monomials pair up in the polynomial. 
For Hamiltonicity, this approach allowed \citeauthor{Björklund14} to utilize 
fast algorithms for computing matrix determinants, which resulted in an 
\bigOstar{1.657^n} time randomized algorithm.

Before we briefly overview the idea behind this algorithm, we define the 
relevant problem:
\begin{problem}
  \problemtitle{\textsc{Hamiltonian path (Hamiltonicity)}}
  \probleminput{An undirected graph $G = (V,E)$.}
  \problemquestion{Does $G$ contain a simple path that visits every vertex?}
\end{problem}

\citeauthor{Björklund14} approached this problem by considering \emph{cycle covers}. 
A cycle cover in a directed graph $D = (V, A)$ is a 
subset $C \subseteq A$ such that for every $v \in V$ there is exactly one arc $a_1 \in C$ ending in $v$ 
and one arc $a_2 \in C$ starting from $v$. One can think of a cycle cover as a set of disjoint 
cycles that cover the entire graph (see Figure \ref{fig:cycle_covers}). 
A \emph{Hamiltonian cycle cover} consists of a single cycle that covers every vertex. 
Note that a Hamiltonian cycle cover trivially implies a Hamiltonian path.

\begin{figure}[h]
  \includegraphics[width=0.8\textwidth, height=5cm]{cycle_covers.png}
  \centering
  \caption{(A) is an undirected graph $G$. (B) showcases an example cycle cover for $G$. 
  Note that an undirected graph can be trivially transformed into a directed graph. 
  (C) is a Hamiltonian cycle cover.}
  \label{fig:cycle_covers}
\end{figure}

In terms of algebrization, 
\citeauthor{Björklund14} essentially formed 
a multivariate polynomial $P$, where the monomials are 
\emph{labels} corresponding 
to cycle covers of the input graph. Evaluating $P$ over a suitable ring, 
non-Hamiltonian cycle covers cancel out, and we detect 
only Hamiltonian cycle covers, i.e., valid solutions to the underlying problem.
%\amnote{This all sounds like magic to me \texttt{:)}}

\citeauthor{Björklund14} achieved this by labeling cycle covers such 
that all non-Hamiltonian cycle covers receive a label identical 
to another non-Hamiltonian cycle cover, 
and Hamiltonian cycle covers receive unique labels. 
Thus, every non-solution monomial has a pair and therefore 
cancels out in characteristic 2, while valid solution monomials survive. 
The design of such labels requires, however, that $G$ be undirected. 
Therefore, this approach can only solve Hamiltonicity for undirected graphs.

For detecting whether $P$ is identical to zero (no solutions exist), \citeauthor{Björklund14} 
employed the same idea of polynomial identity testing as in \Cref{sect:polynomial_identity_testing}.
For achieving the time complexity of \bigOstar{1.657^n}, \citeauthor{Björklund14} 
utilized the natural interpretation of a sum of labeled cycle covers as 
a matrix permanent \cite{Björklund14}.
(In simple terms, the matrix permanent is 
the matrix determinant where every subtraction is replaced with addition.) 
While the permanent is generally very hard to compute, and the determinant is significantly easier, 
they are identical in characteristic 2: there is no distinction between subtraction and addition. 
This essentially allowed \citeauthor{Björklund14} to merely compute a matrix determinant 
to detect a Hamiltonian path, 
and surpass the \bigOstar{2^n} bound 
that is given by the general framework.

\subsection{Other research in detecting multilinear monomials}
\label{sect:other_improvements}

Since the runtime of algebraic fingerprinting is
\amnote*{Why only \enquote{arguably}?}{arguably} optimized for 
the general multilinear monomial detection, much research has been 
done on specific settings. In a series of papers \cite{Chen10, Chen11a, Chen11b, Chen13a}, 
\citeauthor{Chen13a} studied complexities for different types of multivariate
polynomials and
detecting different types of monomials, i.e., \emph{q-monomials}. 
$q$-monomials, i.e. $d$-degree monomials where every exponent is smaller than $d$, 
were also further studied by
\amnote*{Curiously these are different Chens... Can you reformulate text so this
isn't ambiguous?}{\textcite{Chen14}}.

As mentioned in \Cref{sect:derandomization}, algebraic fingerprinting 
relies on randomized methods which are hard to derandomize. 
Much effort \cite{Chen13b, Chen13c, Fomin17, Pratt19, Brand19, Brand21, Brand22} 
has been directed into deterministic algorithms for 
instances of multilinear monomial detection and 
closing the gap between the deterministic and the randomized algorithms. 
The general deterministic $k$-multilinear monomial detection is solved in
in \bigOstar{3.84^k} time \cite{Fomin17}, though methods that result in 
much faster algorithms for specific problems 
have been found. For example, the state-of-the-art deterministic algorithm for $k$-path 
runs in \bigOstar{2.55^k} time by computing partial differentials of multivariate polynomials \cite{Brand21}.

On another front, there has been research in 
extending the application domain of algebraic fingerprinting. 
Specifically, one line of research that has been particularly fruitful 
is \emph{constrained multilinear monomial detection}. 
With constrained multilinear monomial detection \cite{Koutis12, Björklund16}, 
we detect only multilinear monomials that satisfy an additional constraint, 
e.g., a \emph{proper coloring}. 
In coloring, we essentially tie colors to variables. 
A multilinear monomial then satisfies proper coloring 
if the number of occurrences of each color is below some maximum. 
This can be extended to detect solutions with a specific cost \cite{Björklund16} 
and/or temporal properties 
(i.e., we can solve constrained problems that exist in graphs with weights and timestamped vertices) 
\cite{Thejaswi20}.

The evaluation of the polynomial in the algebraic fingerprinting framework is done sequentially. 
However, the matrix representations of the group algebras used 
offer possibilities for parallelization. \textcite{Midas19} observed this and 
optimized distributed algorithms for multilinear monomial detection. 
Using these algorithms, the authors showed applications that outperform the previously 
fastest parallel algorithms in e.g. graph scan statistics (which 
is a methodology that detects anomalies in graphs, see \Cref{sect:related_problems}).

%\clearpage
\section{Conclusion}
\label{sect:conclusion}

From \Cref{sect:related_problems}, 
it can be seen  
that a fast algorithm for $k$-multilinear monomial detection gives a 
fast algorithm for many parameterized combinatorial problems. 
We found that algebraic fingerprinting solves this problem by 
evaluating the given multivariate polynomial over a specific algebraic structure. 
Thus, we 
may say that algebraic fingerprinting gives a general framework for solving 
parameterized combinatorial problems. 

In \Cref{sect:algebraic_fingerprinting}, we discussed the idea behind 
algebraic fingerprinting: generate a polynomial $P(X)$ from the algebrization of 
a combinatorial problem, and evaluate $P(X)$ over $GF(2^{l})[Z_2^k]$ with 
randomized assignments $X \to GF(2^{l})[Z_2^k]$ of form 
$x_i \to (v_0 + v_i)$, augmented with scalar multiplications 
by elements randomly chosen from $GF(2^{l}) \setminus \{\mathbf{0}\}$. 
This gives a randomized algorithm for 
$k$-multilinear monomial detection that runs in \bigOstar{2^k} time.

As mentioned in \Cref{sect:other_improvements}, algebraic fingerprints 
have been studied for deterministic algorithms as well; closing 
the gap between the runtimes of deterministic and randomized algorithms 
has seen great effort, and the gaps for several problems are still bound for improvements.
Furthermore, \Cref{sect:other_improvements} showcases possibilites for extending the 
application domain of algebraic fingerprinting. Applying the general algebraic framework 
to different problem areas is a significant field of interest.

As seen in \Cref{sect:cancel_nonsolutions}, 
the technique of algebraic fingerprints can be utilized for even 
faster randomized algorithms for specific problems. 
In particular, the work of \citeauthor{Björklund14}, which came right
after the novel algebraic technique of \cite{Koutis08}, ended a stagnation of 
nearly fifty years for the well-studied Hamiltonian path problem. 
This sparked developments for several other 
problems as well \cite{Björklund17}, all of which were greatly inspired by 
the general technique of algebraic fingerprints and 
follow similar utilizations of fingerprints as in Hamiltonicity.

However, most of the problems in \Cref{sect:related_problems} are still 
solved most efficiently by the general algebraic framework. Solving these 
specific problems faster or proving that no
improvement is possible 
is still an open problem. 
It may be that 
finding faster algorithms that beat the general algebraic framework requires 
one to design different algebrizations (as in Hamiltonicity) 
or come up with completely new ideas.
